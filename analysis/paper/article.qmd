---
title: "Hire Ed: Job Market Dynamics for Tenure-Track Faculty Positions in Archaeology"
author:
  - Ben Marwick:
      correspondence: "yes"
      email: bmarwick@uw.edu
      orcid: 0000-0001-7879-4531
      institute:
        - uw
  - Anne Marie Poole:
      institute: uw
      orcid: xxx
  - Ailin Zhang:
      institute: uw
      orcid: xxx
  - Setareh Shafizadeh:
      orcid: 0000-0003-2231-4310
      institute: uw
  - Jess Beck:
      orcid: 0000-0002-7387-2307
      institute:
        - ucd
institute:
  - uw: Department of Anthropology, University of Washington, Seattle, USA
  - ucd: School of Archaeology, University College Dublin, Ireland
  
title-block-published: "Last updated"  
date: now
date-format: long
format: 
  docx:
    reference-doc: "../templates/template.docx" # Insert path for the DOCX file
execute:
  echo: false
  warning: false
  message: false
  comment: "#>"
  fig-path: "../figures/"
  fig-dpi: 900
filters:
  - ../templates/scholarly-metadata.lua
  - ../templates/author-info-blocks.lua
  - ../templates/pagebreak.lua
bibliography: references.bib
csl: "../templates/journal-of-archaeological-science.csl" # Insert path for the bib-style
abstract: |
  Academic careers are frequently sought by archaeology graduate students. Job listing websites often serve as the first place for these students when seeking academic positions. We examined tenure-track job advertisements over the past decade to gain insights into the academic job market for archaeologists. Using data from the community-edited Academic Jobs Wiki for Archaeology, we examine changes in the academic job market over time. We studied the text of 449 job ads posted from 2013-2023. Our analysis focuses on shifts in archaeological topics and methods requested in job ads. We investigate whether the burden on applicants has changed over time: do institutions request more information and documents from applicants at the initial stages of application, compared to a decade ago? We also examine whether there is an increasing trend in job advertisements highlighting diversity and inclusivity, thereby encouraging a broader range of applicants. Additionally, we assess the influence of socio-political factors on the changing focus of research topics in the field. This research aims to assist current and future archaeology students and graduates in better understanding the job market and the requirements of employers, thereby aiding them in effectively preparing for their applications for positions in archaeology.
keywords: |
  keyword 1; keyword 2; keyword 3
highlights: |
  These are the highlights. 
---

<!-- This is the format for text comments that will be ignored during renderings. Do not put R code in these comments because it will not be ignored. -->

<!-- With the following code you can access and display values from the yml header above. -->

Keywords: `r rmarkdown::metadata$keywords`

Highlights: `r rmarkdown::metadata$highlights`

<!-- The actual document text starts here: -->

<!-- Instructors to authors for AAQ 

https://documents.saa.org/container/docs/default-source/doc-publications/style-guide/saa-style-guide_english_updated_2021_final08023c15928949dabd02faafb269fb1c.pdf?sfvrsn=c1f41c1b_11

"AAQ recommends 10,000 words for ARTICLES... Total word count includes
the title page, abstracts (English and second language), keywords (English and second language), text, acknowledgments, funding statements, statements of data availability and competing interests, lists of online supplemental material, figure and table captions, text of all tables (for Excel tables, copy and paste into a Word document to check the word count), notes, and the references cited section"

Our notes document: https://docs.google.com/document/d/12FNfuAPIdZPBlKTEZK_HEWM8GwR_ZHyS/edit Ailin: https://docs.google.com/document/d/13OzXGFdZFraEb60ZXGwMUcRxCRKZxAQG/edit & https://docs.google.com/document/d/1NUF6dD8EnStlM6OameVvI9v6ehtf9IpWNt5SCYZgHPQ/edit

Our SAA poster: Poole et al. https://osf.io/p5uzg & https://docs.google.com/presentation/d/1bljiJiE_JmywxRCaUGh4NkkcaMnQNh2uIBUcmxlp-yw/edit#slide=id.g26d90de87be_2_0

Our URS23 poster: Zhang et al. https://docs.google.com/presentation/d/1u9OGBJNRilNBXAsysiY3z4Q5_qOQa4fxxzBfVlZnQYk/edit#slide=id.g2d1d7d9d51d_0_0 

-->

# Introduction

The aim of this paper is to explore the demand-side of the academic job market for archaeologists in the United States. We had two aims: to determine if disciplinary trends can be discerned in the topical, geographic, and method foci of the positions advertised; and to investigate how the requirements for applicants have changed over time. 

# Background

# Methods

Our primary data source is the Archaeology Academic Jobs Wiki. Originating in 2007, this is a set of freely accessible web pages that anyone can edit (anonymously or with a free user account) hosted by Fandom, a for-profit company. The Archaeology pages are part of the Academic Jobs Wiki, which coordinates similar collaboratively-edited resources for around 40 academic disciplines. The coordinators and contributors are nearly all anonymous or pseudonymous. Typically contributors copy and paste the text of job ads from other sources, such as the _Chronicle of Higher Education_, _Higher Ed Jobs_, and university websites, into the wiki, collecting ads originally posted in numerous different locations. Other contributors then edit the web page to add comments below an ad to share relevant information based on their experience in applying for that position, such as a tally of how many people have applied, the dates of events such as requests for more materials, interviews, offer made, rejection notices, etc. Contributors also edit the page to ask and answer questions about the positions and the application process. These comments make the Academic Jobs Wiki a unique resource for timely and specific information for job-seekers about positions they are interested in, and one of the most important internet resources for the academic job market. Because of its reputation for aggregating ads from diverse sources and rapidly-updated information that is not available elsewhere, the Academic Jobs Wiki has a large community of users that keep it updated and accurate has become an authoritative data source for studies of hiring trends in academia [e.g. @musial2018five] and a widely recommended resource [e.g. @lightfoot2021preparing]. 

For each tenure-track job advertised on the Archaeology Academic Jobs Wiki during 2013-2023 we read the text and recorded into a Google form the name of the hiring institution, the title of the position, and exact words and phrases from the ad about the topical, geographic, and methods foci on the position. The topical focus is what we understood as the primary intellectual focus of the position. The geographic focus is the region of the world that the ideal candidate has scholarly expertise on. The methods focus is the data-generating sub-field of archaeology that is mentioned in the ad. We recorded the type and number of documents requested in each ad (e.g. cover letter, CV, statements on research, teaching, diversity, syllabi, course descriptions, writing samples, transcripts) and how many names/letters of recommenders were requested in the ad.

After completing primary data collection, we studied the topical, geographic, and methods foci of each ad and collaboratively and manually reduced the variation in the raw data into 10-15 categories appearing in 20 (for topics and geography) or 10 (for methods) or more job ads to simplify analysis and visualisation. Full details of the category reduction are in our Supplementary Materials. Our topic categories were: American archaeology, Ancient Europe and Mediterranean, Archaeological science, Archaeological theory, Biological anthropology, Complex societies, Digital archaeology, Environmental archaeology, Evolutionary anthropology, Indigenous and Historical archaeology, North Mesoamerican Archaeology, Pleistocene archaeology, and Public archaeology Our geographic categories were: Africa, Americas, Asia & India, Canada & Arctic, Europe, Mediterranean, Meso- & South America, Near East, Oceania, Midwest US, Northeastern US, Southeast US, Southwest US, and Western US. Our methods categories were: Archaeobotany, Archaeometry, Bioarchaeology, Ceramic analysis, Computational and Digital archaeology, Geoarchaeology, Landscape analysis, Lithic analysis, Material culture analysis, and Zooarchaeology. Ads could have multiple or none of these three foci, and some of the foci overlap. Some topics include geographic regions because this is how they are typically understood by archaeologists. For example Mesoamerican archaeology is understood to refer to a specific time period and geographic region. Similarly, digital archaeology we recorded as both a method (when a job ad has a clearly distinct topical focus, such as historic archaeology) and a topic (when there is no other topics mentioned in the job ad). While these overlaps can make the data challenging to interpret, in our view it reflects the complex realities of  how search committees express their needs in searching for new faculty, and is insightful in how it reveals intersections between different foci. 

The entire R code (R Core Team, 2021) and data files used for all the analyses and visualizations contained in this paper are openly available at https://doi.org/xxx/xx to enable re-use of materials and improve reproducibility and transparency (Marwick, 2017). All of the figures, tables, and statistical test results presented here can be independently reproduced with the code and data in this repository. The code is released under the MIT license, the data as CC-0, and the figures as CC-BY, to enable maximum re-use.

# Results

```{r}
#| label: get-data

library(tidyverse)
library(here)
library(ggbeeswarm)
# This CSV file was downloaded from our data sheet here
# https://docs.google.com/spreadsheets/d/1Jwe3UqJyedrV-QWlwR_44__t4xBVrCfxGyhXdi3E0sg/edit?resourcekey#gid=1686084773
# note that you may need to download it again to get the latest updates!

jobdata <- read_csv(here::here('analysis/data/raw_data/Tenure Track Job Advertisements in Archaeology (Responses) - Form Responses 1.csv')) %>% 
  # simplify the column names 
  janitor::clean_names()

total_number_of_ads_in_our_sample <- nrow(jobdata) # 550

# for text on our figures
base_size <- 12
```

```{r}
#| label: fig-how-many-jobs-per-year

# we can get the year from the URL to the Academic Job Ads Wiki

year_ad_posted <- 
jobdata %>% 
  pull(url_to_data_source_e_g_paste_in_url_to_the_jobs_wiki_page) %>% 
  str_extract(.,  "[[0-9]]{4}-[[0-9]]{4}|2021-22") %>% 
  str_replace("2021-22",  "2021-2022") 
 # fix for 2021-22 DONE!
 # fix for 2023 DONE!

jobdata <- 
  jobdata %>% 
  mutate(year_ad_posted = year_ad_posted) %>% 
  drop_na(year_ad_posted) 

```

```{r}
#| label: fig-how-many-jobs-per-year-by-rank

# how many jobs of each rank per year?

jobdata <-
jobdata %>%
  # simplify rank descriptions
  mutate(title_of_position_tenure_track_jobs_only = tolower(title_of_position_tenure_track_jobs_only)) %>%
  mutate(job_title_simple = case_when(
   str_detect(title_of_position_tenure_track_jobs_only,
              "assistant prof|asst. prof|asst prof") ~ "Assistant Professor",
   str_detect(title_of_position_tenure_track_jobs_only,
              "associate prof|assoc. prof") ~ "Associate Professor",
   str_detect(title_of_position_tenure_track_jobs_only,
              "full prof") ~ "Full Professor",
   str_detect(title_of_position_tenure_track_jobs_only,
              "assistant or associate prof|assistant/associate prof") ~ "Assistant or Associate Professor",
   str_detect(title_of_position_tenure_track_jobs_only,
              "open rank|open-rank|assistant, associate, or full prof|assistant prof, associate prof, or prof") ~ "Open Rank",
   .default = "Other (Curator, Director, etc.)"))

# explore over time
fig_prop_by_job_title_per_year <- 
jobdata %>%
  group_by(year_ad_posted) %>%
  count(job_title_simple) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot() +
  aes(year_ad_posted,
      n,
      group = job_title_simple,
      fill = job_title_simple) +
 # geom_line(linewidth = 2) +
  geom_col() +
 theme_minimal(base_size = base_size) +
  xlab("") +
  ylab("Number of\ntenure track job ads") +
  scale_fill_brewer(palette = "Dark2") +
  guides(fill = guide_legend(nrow=2,
                               byrow=TRUE,
                               "Job title",
                                keywidth=0.1,
                 keyheight=0.1,
                 default.unit="inch")) +
    theme(legend.position = c(0.5, 0.85)) +
  guides(x = "none")

```

```{r}
#| label: ratio-tt-to-non-tt

base_url_to_2019 <- "https://academicjobs.fandom.com/wiki/Archaeology_Jobs_"
base_url_after_2020 <- "https://academicjobs.fandom.com/wiki/Archaeology_"

# starts at 2010-2011
# fix for 2021-22
# base UR

years_to_2019 <- map_chr(2012:2019, ~str_glue('{.x}-{.x +1}'))
years_after_2020 <- map_chr(2020:2022, ~str_glue('{.x}-{.x +1}'))
# though it seems to start at 2007-8: https://academicjobs.fandom.com/wiki/Archaeology_07-08

# make a set of URLs for each page for each year
urls_for_each_year <- c(str_glue('{base_url_to_2019}{years_to_2019}'), 
                        str_glue('{base_url_after_2020}{years_after_2020}')) %>% 
    str_replace("2021-2022", "2021-22")
```

```{r}
#| eval: false

library(rvest)

# scrape the web pages to get the 
# ratio of tenure-track to untenured positions
# base URL changes after 2018_2019
# We did this once and then saved the output so we don't scrape every
# time the quarto document is rendered. So this code block is
# eval: false to avoid repeated and unnesecary scraping

# all years
urls_for_each_year_headers <- 
map(urls_for_each_year,
    ~.x %>% 
      read_html() %>% 
      html_nodes('.mw-headline') %>% 
      html_text())

# save this list so we don't have to scrape again
library(rlist)
list.save(urls_for_each_year_headers, 
          here('analysis/data/raw_data/urls_for_each_year_headers.yaml'))
```

```{r}
#| label: ratio-tt-to-non-tt-jobs

library(rlist)
urls_for_each_year_headers <-  list.load( here('analysis/data/raw_data/urls_for_each_year_headers.yaml'))

# keep only headings that are actual jobs, they include the terms:
job_headings <- c("college", "university")

total_number_of_jobs_per_year <- 
  map(urls_for_each_year_headers,
      ~str_subset(tolower(.x),
          paste0(job_headings, collapse = "|")))

total_number_of_jobs_per_year_n <- 
map_int(total_number_of_jobs_per_year, length)

total_number_of_jobs_per_year_tbl <- 
tibble(
  url_to_data_source_e_g_paste_in_url_to_the_jobs_wiki_page = urls_for_each_year,
  total_number_of_jobs_per_year = total_number_of_jobs_per_year_n
)

# count of TT jobs per year from our manual data collection,
# join with our total number of all jobs by scraping
count_of_tt_jobs_per_year_from_our_form <- 
jobdata %>% 
  group_by(url_to_data_source_e_g_paste_in_url_to_the_jobs_wiki_page) %>% 
  tally() %>% 
  right_join(total_number_of_jobs_per_year_tbl) %>% 
  rename(n_tt_jobs  = n,
         n_total_jobs = total_number_of_jobs_per_year) %>% 
  mutate(n_non_tt_jobs = n_total_jobs - n_tt_jobs,
         ratio_tt_2_ntt = n_tt_jobs / n_non_tt_jobs) %>% 
  mutate(year = str_extract(url_to_data_source_e_g_paste_in_url_to_the_jobs_wiki_page,  "[[0-9]]{4}-[[0-9]]{4}|2021-22")) %>%  
  mutate(year = ifelse(year =="2021-22",  "2021-2022", year))  %>% 
  # add line break for prettier plotting
  mutate(year_ad_posted_break = str_replace(year, "-", "-\n"))
  

# draw plot
fig_ratio_tt_2_ntt_jobs_per_year <- 
  ggplot(count_of_tt_jobs_per_year_from_our_form) +
  aes(year_ad_posted_break, 
      group = 1,
      ratio_tt_2_ntt) +
  #geom_line(linewidth = 2) +
  geom_col() +
  geom_hline(yintercept = 1,
             colour = "red") +
  annotate("text", 
           x = 6, 
           y = 1.4, 
           label = "1:1 ratio",
           colour = "white",
           size = 3) +
  labs(y = "Ratio of tenure-track\nto non-tenure track and other",
       x = "") +
  theme_minimal(base_size = base_size) +
  scale_x_discrete(name = "Academic Year") 
   #guides(x = "none")
  

```

```{r}
#| label: combine-basic-plots

# save these three plots as one set
library(cowplot)
p <- 
plot_grid(
  fig_prop_by_job_title_per_year + theme(plot.margin = unit(c(0, 0, 0, 0), "cm")),
  fig_ratio_tt_2_ntt_jobs_per_year + theme(plot.margin = unit(c(0, 0, 0, 0), "cm")),

  ncol = 1,
  align = "hv",
  axis = "lr",
  labels = "AUTO",
  label_size = 8
)

ggsave(filename = here("analysis",
            "figures", 
            "fig-panel-per-year.png"),
       bg ="white",
      plot = p,
       h = 5, # experiment with h and w to get the right size and proportion 
       w = 7,
       units = "in",
       dpi = 900) # make the image nice and crisp

```

```{r}
#| label: fig-show-basic-plots
#| fig-cap: "A: total number of job ads posted to the Academic Jobs Wiki for Archaeology in each year, with coloured sections showing the proportion of jobs by title and rank. B: Ratio of tenure-track to non-tenure-track positions over time."

# show figure from PNG file
knitr::include_graphics(here("analysis",
            "figures", 
            "fig-panel-per-year.png"))
```

We collected data from `r total_number_of_ads_in_our_sample` ads for tenure-track jobs in archaeology posted during 2013-2023. @fig-show-basic-plots shows the count of ads for each year. Assistant Professor jobs are consistently the most common title and rank, and open rank or full professor are the least frequent. The ratio of tenure-track to non-tenure track positions is generally well above one.  Only 2013-2014 had more non-tenure track positions than tenure track, which was followed by an upward trend peaking at 2018-2019 and the declining again into the present.

## Characteristics of the hiring institutions

```{r}
# Draw of map to show which states have done the most hiring in our sample

# get the text in parentheses after the university name that gives the
# state or country abb
uni_state_country <- # 550
jobdata %>%  # 550 rows
 select(name_of_hiring_university) %>%
  mutate(state_country = regmatches(name_of_hiring_university,
                                    gregexpr( "(?<=\\().+?(?=\\))",
                                              name_of_hiring_university,
                                              perl = T))) %>%
  unnest(state_country)

# tally to get counts:
uni_state_country_tally <-
uni_state_country %>%
  group_by(state_country) %>%
  tally(sort = TRUE)

# did we get all the job ads?
# sum(uni_state_country_tally$n) # 550 all of them

state_to_st <- function(x){
       c(state.abb, 'DC')[match(x, c(state.name, 'District of Columbia'))]
}

state_name_and_abb <-
enframe(state.name, value = 'state_name') %>%
       mutate(state_abbr = state_to_st(state_name))

# filter to get US states only
uni_state_country_tally_us <-
uni_state_country_tally %>%
  filter(state_country %in% state.abb) %>%
  select(state_abbr = state_country, n) %>%
  # make sure we have all states in the dataframe
  # even those with no jobs
  right_join(state_name_and_abb) %>%
  select(state = state_name, n, state_abbr) %>%
  mutate(state = tolower(state)) %>%
  mutate(n = ifelse(is.na(n), 0, n))

# how many jobs ads now?
# sum(uni_state_country_tally_us$n) # 433, 78% of the total

library(ggplot2)
library(fiftystater)
library(tidyverse)
library(ggrepel)

data("fifty_states")

p_map <- 
ggplot(data= uni_state_country_tally_us,
       aes(map_id = state)) +
  geom_map(aes(fill = n),
           color= "black",
           linewidth = 0.1,
           map = fifty_states) +
  expand_limits(x = fifty_states$long,
                y = fifty_states$lat) +
  coord_map() +
  geom_text_repel(data = fifty_states %>%
              group_by(id) %>%
              summarise(lat = mean(c(max(lat), min(lat))),
                        long = mean(c(max(long), min(long)))) %>%
              mutate(state = id) %>%
              left_join(uni_state_country_tally_us,
                        by = "state"),
            aes(x = long,
                y = lat,
                label = n,
                bg.color = "white",
                bg.r = 0.1),
            force = 0,
            force_pull = 100,
            size = 3)+
  scale_x_continuous(breaks = NULL) +
  scale_y_continuous(breaks = NULL) +
  labs(x = "",
       y = "") +
  theme(legend.position = "bottom",
        panel.background = element_blank()) +
  scale_fill_viridis_c()

ggsave(plot = p_map, 
       filename = here("analysis",
            "figures",
            "fig-us-state-map.png"),
       bg ="white",
       h = 10, # experiment with h and w to get the right size and proportion
       w = 12,
       units = "in",
       dpi = 900) # make the image nice and crisp))
```

```{r}
# Carnegie Classification
library(stringi)
library(readxl)

# data from https://carnegieclassifications.acenet.edu/resource/2021-update-public-file/
CC <-
  read_excel(here::here('analysis/data/raw_data/CCIHE2021-PublicData.xlsx'),
              sheet = "Values1")
Basic2021 <-
  read_excel(here::here('analysis/data/raw_data/CCIHE2021-PublicData.xlsx'),
             sheet = "Data1") 
  # remove a bunch of text from uni names to improve our joins

uni_name <- # 547
 jobdata %>%  # 547 rows
  # remove parentheses and their contents
  mutate(name = str_squish(str_replace(name_of_hiring_university,
                            "\\s*\\(.*?\\)$", 
                            ""))) %>% 
  mutate(name = str_replace(name,
                            "California State University,[[:space:]]",
                            "California State University-")) %>% 
  left_join(Basic2021, 
            keep = TRUE ) 

# how many schools did we match with the CC data
hm_schools_match <- 
uni_name %>% 
  filter(!is.na(basic2021)) %>% 
  nrow() # 245, 290, 300, 313, 404, 430 / 433 for US unis

# which schools don't match with the CC data?
no_match <- 
uni_name %>% 
  select(name.x, name.y)  %>% 
  filter(is.na(name.y)) %>% 
  distinct() 

uni_name_tally <- 
uni_name %>% 
  left_join(CC,
            join_by("basic2021" == "Value")) %>% 
  group_by(Category) %>% 
  tally(sort = TRUE) %>% 
  drop_na()

p_c <- 
uni_name_tally %>% 
  mutate(Category = str_wrap(Category, width = 30)) %>% 
ggplot() +
  aes(reorder(Category, n), n) +
  geom_col() +
  coord_flip() +
  xlab("") +
  theme_minimal(base_size = 14)

library(cowplot)
p_map_c <- 
ggdraw(p_c) +
  draw_plot(p_map, .4, .1, .65, .65) +
  draw_plot_label(
    c("A", "B"),
    c(0, 0.45),
    c(1, 0.65),
    size = 12
  )

ggsave(here("analysis",
            "figures", 
            "fig-map-and-carnegie-classification.png"),
       plot = p_map_c,
       bg ="white",
       h = 7, # experiment with h and w to get the right size and proportion
       w = 12,
       units = "in",
       dpi = 900) # make the image nice and crisp))

```

```{r}
#| label: fig-show-map-of-hiring-institution-and-cc
#| fig-cap: "A: Frequency of hiring institution by Carnegie classification. B: Inset shows map of the United States showing the count of tenure-track job ads posted by all insititutions in each state during 2013-2023"

# show figure from PNG file
knitr::include_graphics(here("analysis",
            "figures",
            "fig-map-and-carnegie-classification.png"))
```

Panel A of @fig-show-map-of-hiring-institution-and-cc shows the frequencies of institutions according to their Carnegie Classification, which is a framework for classifying US colleges and universities according to the types of degrees awarded, levels of activity such as research, and topical foci. Doctoral universities with high and very high research activity are by far the most active with hiring archaeology faculty. Associate's colleges, also known as community colleges, rarely post job ads for archaeology faculty.  

Panel B of @fig-show-map-of-hiring-institution-and-cc shows the geographic distribution of the hiring institutions. California posted almost twice as many job ads as the next most active states. After California, the states that posted the most ads during 2013-2023 include New York, Texas, and Pennsylvania, and Florida. These top five states also correspond to the top five most populous US states, indicating that rates of hiring is approximately proportional to population density. Similarly, the lowest counts of job ads were observed in states with the lowest populations: North Dakota, South Dakota, Alaska, and Nebraska. No institutions in Montana posted a job ad during this period.

## Geographic trends over time in job ads

```{r}
#| label: fig-geographic-focus-by-year 

# geographic focus by year

library(stringi)

geographic_foci <-
  read_csv(here("analysis/data/raw_data/Tenure Track Job Advertisements in Archaeology - geography.csv"))

geographic_foci_clean <-
  map(
   str_split(geographic_foci$`From the data`, ";"),
   ~.x %>%
     str_squish() %>%
     stri_remove_empty())

jobdata_geo <-
  jobdata %>%
  select(geographic_focus_of_position)

jobdata_geo <-
  # add one column for each geo region in our categories
cbind(jobdata_geo,
      setNames( lapply(geographic_foci$Category2, function(x) x=NA),
                geographic_foci$Category2) )

for(i in 1:length(geographic_foci$Category2)){

  this_location <- geographic_foci$Category2[i]

  # create the pattern to search for
  x <- paste0(geographic_foci_clean[[i]], collapse = "|")

  # do the search through all the job ads for that pattern
  y <- str_detect(jobdata_geo$geographic_focus_of_position,
             x)

  # assign back to our data frame in the appropriate location column
  jobdata_geo[, this_location] <- y

}

# BM TODO: check for job ads that have a location, but we're not getting it

united_states_regions <-
str_subset(geographic_foci$Category2, "US")

jobdata_geo_year <-
jobdata %>%
  bind_cols(jobdata_geo) %>%
  select(year_ad_posted,
         geographic_foci$Category2) %>%
  pivot_longer(-year_ad_posted) %>%
  drop_na()

# how many times each location mentioned?
p_locations <- 
jobdata_geo_year %>%
  group_by(name) %>%
  summarise(n = sum(value)) %>%
  arrange(desc(n)) %>%
  ggplot() +
  aes(reorder(name, n),
      n)+
  geom_col() +
  xlab("") +
  theme_minimal() +
  coord_flip()

# explore trends over time. put a point on the max year
jobdata_geo_year_tally <-
jobdata_geo_year %>%
 # exclude those with <20 ads
  filter(!name %in% c("Canada & Arctic",
                      "Oceania",
                      "Southeast US",
                      "Southwest US",
                      "Western US",
                      "Midwest US",
                      "Northeastern US"
                      )) %>%
  group_by(year_ad_posted,
           name) %>%
  summarise(n = sum(value)) %>%
  mutate(prop = n / sum(n)) %>% 
  # add line break for prettier plotting
  mutate(year_ad_posted_break = str_replace(year_ad_posted, "-", "-\n"))

jobdata_geo_year_tally_max <-
  jobdata_geo_year_tally %>%
  group_by(name ) %>%
  filter(prop == max(prop))

library(ggrepel)

p_geo_year <- 
ggplot() +
  geom_jitter(data =  jobdata_geo_year_tally,
              alpha = 0.3, size = 4,
            aes(year_ad_posted_break,
                 prop,
                 group = name,
                 colour = name)) +
  geom_smooth(data =  jobdata_geo_year_tally,
            aes(year_ad_posted_break,
                 prop,
                 group = name,
                 colour = name),
            linewidth = 3,
           se = FALSE 
           ) +
  xlab("") +
  ylab("Proportion of all ads") +
  scale_colour_brewer(palette = "Dark2") +
  guides(colour = guide_legend("Geographic\nfocus",
                               label.position = "bottom")) +
    theme_minimal( base_size = base_size) +
  theme(legend.position="bottom") 

p_geo <- 
plot_grid(p_locations, 
          p_geo_year,
          ncol = 1,
          rel_heights =  c(0.5, 1.5),
          labels = "AUTO")

ggsave(here("analysis",
            "figures", 
            "fig-geo-focus-by-year.png"),
       bg ="white",
       h = 10, # experiment with h and w to get the right size and proportion 
       w = 8,
       units = "in",
       dpi = 900) # make the image nice and crisp)


# what about within the US
# how many times each location mentioned?
p <- 
jobdata_geo_year %>%
  group_by(name) %>%
  summarise(n = sum(value)) %>%
  arrange(desc(n)) %>%
  filter(name %in% united_states_regions) %>% 
  ggplot() +
  aes(reorder(name, n),
      n)+
  geom_col() +
  ylab("Number of ads") +
  xlab("") +
  theme_minimal(base_size = 24) +
  coord_flip()
```

```{r}
#| label: fig-show-geo-trends
#| fig-cap: "A: Frequency of locations mentioned in the text of the job ads. B: Popularity of locations in job ads over time. Individual data points are show, overlain by a locally weighted regression line for each location to indicate temporal trends."

# show figure from PNG file
knitr::include_graphics(here("analysis",
            "figures",
            "fig-geo-focus-by-year.png"))
```

We recorded all geographic regions mentioned in the text where the successful applicant should have expertise and be research active. Our analysis focuses on those locations mentioned in 20 or more ads Overall, American locations dominate. Panel A of @fig-show-geo-trends shows that a single region of the US, the Southwest, occurs in more job ads than every other part of the world except for the Mediterranean. The Southwest includes Arizona and New Mexico, with portions of California, Colorado, Nevada, Oklahoma, Texas, and Utah. It is archaeologically significant as the home of the Ancestral Pueblo, Hohokam, and Mogollon peoples who practiced irrigation agriculture and lived in relatively large settlements, compared to other regions of the US. The area was later occupied by the Navajo, Ute, Southern Paiute, Hopi and Zuni, also in relatively large numbers. The Mediterranean is prominent because it is the location that is often mentioned in job ads focused on classical archaeology (i.e. archaeology of Bronze and Iron Age Italy and Greece). 

Demand for jobs focusing on the Americas is generally high over time, with a peak in 2019-2020, and a decrease since then. Demand for jobs focusing on Africa was very low until 2019-2020, peaking in 2020-2021. The proportion of ads with a geographic focus on the Mediterranean has varied substantially, peaking at 2016 and at its lowest in 2019, showing an inverse pattern of the Americas. Asia and India, the Near East and Europe are consistently rare as a geographical focus in job ads. Asia and India, Africa and the Americas appear correlated with each other, while the Near East and Mediterranean are correlated in an opposite trend.

## Method trends over time

```{r}
# method focus by year

library(stringi)

method_foci <-
  read_csv(here("analysis/data/raw_data/Tenure Track Job Advertisements in Archaeology - method.csv"))

method_foci_clean <-
  map(
    str_split(method_foci$`From the data`, ";"),
    ~.x %>%
      str_squish() %>%
      stri_remove_empty() %>%
      str_to_lower)

jobdata_method <-
  jobdata %>%
  select(methods_focus_of_position) %>%
  mutate(methods_focus_of_position = str_to_lower(methods_focus_of_position))

jobdata_method <-
  # add one column for each topic in our categories
  cbind(jobdata_method,
        setNames( lapply(method_foci$Category, function(x) x=NA),
                  method_foci$Category) )

for(i in 1:length(method_foci$Category)){

  this_method <- method_foci$Category[i]

  # create the pattern to search for
  x <- paste0(method_foci_clean[[i]], collapse = "|")

  # do the search through all the job ads for that pattern
  y <- str_detect(jobdata_method$methods_focus_of_position,
                  x)

  # assign back to our data frame in the appropriate location column
  jobdata_method[, this_method] <- y

}

jobdata_method_year <-
  jobdata %>%
  bind_cols(jobdata_method) %>%
  select(year_ad_posted,
         method_foci$Category) %>%
  pivot_longer(-year_ad_posted) %>%
  drop_na()  %>% 
  mutate(name = case_when(
    name == "Computational and Digital archaeology" ~ "Computational and\ndigital archaeology",
    name == "Material culture analysis" ~ "Material culture\nanalysis",
    .default = name))  

# how many times each topic mentioned?
p_method <- 
jobdata_method_year %>%
  group_by(name) %>%
  summarise(n = sum(value)) %>%
  arrange(desc(n)) %>%
  ggplot() +
  aes(reorder(name, n),
      n)+
  geom_col() +
  xlab("") +
    theme_minimal(base_size = base_size) +
  theme(axis.text.y  = element_text(size = 7)) +
  coord_flip()

# explore trends over time. put a point on the max year
jobdata_method_year_tally <-
  jobdata_method_year %>%
  # exclude those with <20 ads
  filter(!name %in% c("Material culture\nanalysis",
                      "Ceramic analysis"
  )) %>%
  group_by(year_ad_posted,
           name) %>%
  summarise(n = sum(value)) %>%
  mutate(prop = n / sum(n)) %>% 
  # add line break for prettier plotting
  mutate(year_ad_posted_break = str_replace(year_ad_posted, "-", "-\n"))

library(ggrepel)

p_method_trend <- 
ggplot() +
    geom_jitter(data =  jobdata_method_year_tally,
              alpha = 0.3, size = 4,
            aes(year_ad_posted_break,
                 prop,
                 group = name,
                 colour = name)) +
  geom_smooth(data =  jobdata_method_year_tally,
            aes(year_ad_posted_break,
                prop,
                group = name,
                colour = name),
            size = 3,
            se = FALSE) +
  xlab("Year") +
  ylab("Proportion of all ads") +
  guides(colour = guide_legend("Method\nfocus",
                               label.position = "bottom")) +
    theme_minimal( base_size = base_size) +
  scale_colour_brewer(palette = "Dark2") +
  theme(legend.position="bottom") 

p_meth <- 
plot_grid(p_method, 
          p_method_trend,
          ncol = 1,
          rel_heights =  c(0.5, 1.5),
          labels = "AUTO")

ggsave(here("analysis",
            "figures", 
            "fig-method-focus-by-year.png"),
       plot = p_meth, 
       bg ="white",
       h = 10, # experiment with h and w to get the right size and proportion
       w = 8,
       units = "in",
       dpi = 900) # make the image nice and crisp))
```

```{r}
#| label: fig-show-metho-trends
#| fig-cap: "A: Frequency of methods mentioned in the text of the job ads. B: Popularity of methods in job ads over time. Individual data points are show, overlain by a locally weighted regression line for each location to indicate temporal trends."

# show figure from PNG file
knitr::include_graphics(here("analysis",
            "figures",
            "fig-method-focus-by-year.png"))
```

Landscape archaeology, encompassing GIS and remote sensing, has remained prominent compared to other methods [@fig-show-metho-trends]. Methods focused on a specific element of the archaeological record, such as Lithic analysis, Zooarchaeology and Ceramics are among the least frequently mentioned in job ads. Instead we see the more popular methods here are ones that are relevant to multiple elements of the archaeological record (e.g. Archaeobotany encompasses macroscopic and microscopic plant remains; Bioarchaeology may include skeletal analysis, isotopes, protiens, etc.). 

Landscape archaeology, although dominant has fluctuated over the years and has been on a downtrend since 2018-2019. Computational and digital archaeology is the second most represented method, showing an overall increasing trend, particularly since 2020-2021. Archaeobotany shows a strong cyclical trend, with a rise and fall and rise again over our study period. Archaeometry and Geoarchaeology have maintained a relatively low but steady presence in job ads, peaking in 2017-2018 and 2018-2019 and declining thereafter. Lithic analysis and Zooarchaeology are also mentioned relatively infrequently in job ads and show an inverse correlation with each other after 2018-2019. 

## Topic trends over time

```{r}

# topical focus by year
library(stringi)

topical_foci <-
  read_csv(here("analysis/data/raw_data/Tenure Track Job Advertisements in Archaeology - topic.csv"))

topical_foci_clean <-
  map(
    str_split(topical_foci$`From the data`, ";"),
    ~.x %>%
      str_squish() %>%
      stri_remove_empty() %>%
      str_to_lower)

jobdata_topic <-
  jobdata %>%
  select(topical_focus_of_position) %>%
  mutate(topical_focus_of_position = str_to_lower(topical_focus_of_position))

jobdata_topic <-
  # add one column for each topic in our categories
  cbind(jobdata_topic,
        setNames( lapply(topical_foci$Category, function(x) x=NA),
                  topical_foci$Category) )

for(i in 1:length(topical_foci$Category)){

  this_topic <- topical_foci$Category[i]

  # create the pattern to search for
  x <- paste0(topical_foci_clean[[i]], collapse = "|")

  # do the search through all the job ads for that pattern
  y <- str_detect(jobdata_topic$topical_focus_of_position,
                  x)

  # assign back to our data frame in the appropriate location column
  jobdata_topic[, this_topic] <- y

}

jobdata_topic_year <-
  jobdata %>%
  bind_cols(jobdata_topic) %>%
  select(year_ad_posted,
         topical_foci$Category) %>%
  pivot_longer(-year_ad_posted) %>%
  drop_na() %>% 
  # add line break for prettier plotting
  mutate(year_ad_posted_break = str_replace(year_ad_posted, "-", "-\n"))

# how many times each topic mentioned?
p_topic <- 
jobdata_topic_year %>%
  group_by(name) %>%
  summarise(n = sum(value)) %>%
  arrange(desc(n)) %>%
  ggplot() +
  aes(reorder(name, n),
      n)+
  geom_col() +
  xlab("") +
  theme_minimal() +
  coord_flip()

# explore trends over time. put a point on the max year
jobdata_topic_year_tally <-
  jobdata_topic_year %>%
  # exclude those with <20 ads
  filter(!name %in% c("Digital Archaeology",
                      "Digital archaeology",
                      "Pleistocene archaeology",
                      "Mesoamerican Archaeology",
                      "Biological anthropology",
                      "Archaeological theory",
                      "Evolutionary anthropology",
                      "North American archaeology"
  )) %>%
  group_by(year_ad_posted,
           name) %>%
  summarise(n = sum(value)) %>%
  mutate(prop = n / sum(n))  %>% 
  # add line break for prettier plotting
  mutate(year_ad_posted_break = str_replace(year_ad_posted, "-", "-\n"))

jobdata_topic_year_tally_max <-
  jobdata_topic_year_tally %>%
  group_by(
    name ) %>%
  filter(prop == max(prop)) 

library(ggrepel)

p_topic_trend <- 
ggplot() +
      geom_jitter(data =  jobdata_topic_year_tally,
              alpha = 0.3, size = 4,
            aes(year_ad_posted_break,
                 prop,
                 group = name,
                 colour = name)) +
  geom_smooth(data =  jobdata_topic_year_tally,
            aes(year_ad_posted_break,
                prop,
                group = name,
                colour = name),
            size = 3,
            se = FALSE) +
  xlab("Year") +
  ylab("Proportion of all ads") +
  scale_colour_brewer(palette = "Dark2") +
  guides(colour = guide_legend("Topic\nfocus",
                               label.position = "bottom")) +
    theme_minimal( base_size = base_size) +
  theme(legend.position="bottom") 

p_topi <- 
plot_grid(p_topic, 
          p_topic_trend,
          ncol = 1,
          rel_heights =  c(0.5, 1.5),
          labels = "AUTO")

ggsave(here("analysis",
            "figures", 
            "fig-topic-focus-by-year.png"),
       plot = p_topi, 
       bg ="white",
       h = 10, # experiment with h and w to get the right size and proportion
       w = 8,
       units = "in",
       dpi = 900) # make the image nice and crisp))
```

```{r}
#| label: fig-show-topi-trends
#| fig-cap: "A: Frequency of methods mentioned in the text of the job ads. B: Popularity of methods in job ads over time for topics that appear in 20 or more ads. Individual data points are shown, overlain by a locally weighted regression line for each location to indicate temporal trends."

# show figure from PNG file
knitr::include_graphics(here("analysis",
            "figures",
            "fig-topic-focus-by-year.png"))
```

The most frequently mentioned topic in the job ads in Environmental archaeology [@fig-show-topi-trends], which is our category for phrases found in the text of ads such as human-environmental dynamics, interaction between humans and their environments, environmental change, climate change, historical ecology, ecological knowledge,human ecology, and ecological systems. Public archaeology is the second most frequent topic overall, this includes phrases such as cultural resource management, cultural heritage, heritage studies, museum studies, human rights, community engaged, historic preservation; social justice, community-based,  repatriation, and community-engaged archaeology. The least frequent topics are Pleistocene archaeology, e.g. human origins; hunter-gatherer archaeology, and digital archaeology. 

In the years 2019-2020 and 2020-2021 there are striking changes in the popularity of topics in job ads. Indigenous and historical archaeology became the most popular topic at this time, rising from being one of the least popular topics from 2012-2017. Conversely, archaeological science, which was popular during 2012-2017, was rarely mentioned in job ads during 2019-2021. Ancient Europe and the Mediterranean, which was consistently one of the least frequently mentioned topics, virtually disappeared from job ads during 2019-2021. Mentions  of complex societies in ads consistently decrease over the study period, while mentions of public archaeology consistently increase. The topic of Environmental Archaeology remains consistently high over time. 

```{r}
#| label: richness-in-ads


# geo co-occurance
jobdata_geom_cooc <- 
  jobdata_geo %>% 
  select(-geographic_focus_of_position) %>% 
  drop_na()  %>% 
  mutate_all(as.numeric)

# topic co-occurance
jobdata_topic_cooc <- 
jobdata_topic %>% 
  select(-topical_focus_of_position) %>% 
  drop_na()  %>% 
  mutate_all(as.numeric)

# method co-occurance
jobdata_method_cooc <- 
  jobdata_method %>% 
  select(-methods_focus_of_position) %>% 
  drop_na()  %>% 
  mutate_all(as.numeric)


kw_test_richness_input <- 
map(
  list(jobdata_topic_cooc,
       jobdata_method_cooc,
       jobdata_geom_cooc),
  ~rowSums(.x)) %>% 
  imap(~ data.frame(group = .y, value = .x)) %>%
  bind_rows() 

kw_test_richness <- 
  kruskal.test(kw_test_richness_input, 
               value ~ group)

# from https://stackoverflow.com/a/61758180/1036500 for pretty printing
expSup <- function(w, digits=0) {
  sprintf(paste0("%.", digits, "f*x*10^%d^"), w/10^floor(log10(abs(w))), floor(log10(abs(w))))
}
```

```{r}
# plot topic co-occurance

# Calculate co-occurrence matrix
cooccurrence_matrix <- t(jobdata_topic_cooc) %*% as.matrix(jobdata_topic_cooc)

# Convert to a tidy format for easy inspection and manipulation
cooccurrence_tidy <- as.data.frame(as.table(as.matrix(cooccurrence_matrix)))

# Rename the columns for better readability
colnames(cooccurrence_tidy) <- c("Variable1", "Variable2", "Cooccurrence")

# View the top co-occurring variable pairs
cooccurrence_tidy_df <- 
cooccurrence_tidy %>%
  filter(Variable1 != Variable2) %>%  # Exclude diagonal (self-co-occurrence)
  filter(as.numeric(Variable1) < as.numeric(Variable2)) %>% 
  arrange(desc(Cooccurrence)) %>% 
  drop_na()

library(viridis)

# Plot heatmap of co-occurrence matrix
p_coo <- 
ggplot(cooccurrence_tidy_df, 
       aes(Variable1, Variable2, fill = Cooccurrence)) +
  geom_tile() +
  scale_fill_viridis(option = "viridis") +
  theme_minimal(base_size  = base_size) +
  guides(fill = guide_colorbar(title.position = "top")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(angle = 45, hjust = 1),
        legend.position = c(.7,.2),
        legend.direction = "horizontal") +
  coord_equal() +
  labs(x = "", y = "") 

ggsave(here("analysis",
            "figures", 
            "fig-topic-cooc-heatmap.png"),
       plot = p_coo, 
       bg ="white",
       h = 8, # experiment with h and w to get the right size and proportion
       w = 8,
       units = "in",
       dpi = 900) # make the image nice and crisp))

```

```{r}
#| label: fig-show-cooc
#| fig-cap: "Heatmap of topic co-occurrance in job ads."

# show figure from PNG file
knitr::include_graphics(here("analysis",
            "figures",
            "fig-topic-cooc-heatmap.png"))
```

Job ads are frequently rich in topics, that is, they mention multiple topics in a single call for applications, more often than they mention multiple methods or geographic locations. A Kruskal-Wallis test indicated significantly higher richness in topics compared to richness of geographic locations or methods in job ads (χ2 (df = `r unname(kw_test_richness$df)`, N = `r nrow(kw_test_richness_input)`)  = `r round(unname(kw_test_richness$statistic), 2)`, p = `r expSup(unname(kw_test_richness$p.value))`). @fig-show-cooc shows topic co-occurrences in our sample. Indigenous and historical archaeology often occurs in job ads with Public archaeology and North American archaeology. Complex societies and environmental archaeology were frequently found in the same ads. Biological archaeology, archaeological science, and evolutionary archaeology are another cluster of topics that frequently occur together. Other topics are relatively isolated, for example, Pleistocene archaeology and digital archaeology rarely occur with other topics.



## Instructions to applicants over time


```{r}
#| label: requirements-over-time

# look at only these requirements because the others are flat

intresting_requirements <- 
c("cover letter",
  "cv",
  "names of recommenders",
  "diversity statement",
  "research statement",
  "teaching statement")

jobdata_requirements <- 
jobdata %>% 
  select(year_ad_posted,
         starts_with("documents_requested")) %>% 
  pivot_longer(-year_ad_posted) %>% 
  mutate(value = case_when(
    value == "Not requested in the job ad" ~ 0,
    value == "One" ~ 1,
    value == "Two (e.g. two syllabi)" ~ 2,
    value == "Three" ~ 3,
    .default = 0
  ))  %>% 
  # trim names a bit
  mutate(name = str_remove(name, "documents_requested_")) %>% 
  mutate(name = str_replace_all(name, "_", " ")) %>% 
  filter(name %in% intresting_requirements) %>% 
  mutate(name = str_wrap(name, 30),
         year_ad_posted = str_replace(year_ad_posted, "-", "\n")) %>% 
  # add line break for prettier plotting
  mutate(year_ad_posted_break = str_replace(year_ad_posted, "-", "-\n"))

jobdata_requirements_means <- 
jobdata_requirements %>% # average number requested per year
  group_by(year_ad_posted, 
           name) %>% 
  summarise(mean_n = mean(value)) %>% 
  # add line break for prettier plotting
  mutate(year_ad_posted_break = str_replace(year_ad_posted, "-", "-\n"))

integer_breaks <- function(n = 5, ...) {
  fxn <- function(x) {
    breaks <- floor(pretty(x, n, ...))
    names(breaks) <- attr(breaks, "labels")
    breaks
  }
  return(fxn)
}

p_req <- 
ggplot(jobdata_requirements_means) +
  aes(year_ad_posted_break, 
      mean_n,
      group = name) +
  geom_smooth(linewidth = 2,
              colour = "black") +
  geom_jitter(data = jobdata_requirements,
             aes(year_ad_posted_break, 
                 value),
             alpha = 0.1,
             height = 0.2,
             width =  0.1) +
  facet_wrap(~name,
             scales = "free_y",
             nrow = 2) +
  xlab("") +
  ylab("Number requested in job ad") +
  scale_y_continuous(breaks = integer_breaks()) +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(size = 8),
        strip.text = element_text( size = 16))

ggsave(filename = here("analysis",
            "figures", 
            "fig-requirements-per-year.png"),
       plot = p_req,
       bg ="white",
       h = 6, # experiment with h and w to get the right size and proportion 
       w = 12,
       units = "in",
       dpi = 900) # make the image nice and crisp
  
```

```{r}
#| label: fig-requirements-over-time
#| fig-cap: "Changing requirements in job ads over time. Each point represents an individual job ad. The points have been jittered to avoid overlap. The black line is a locally weighted regression line to identify temporal trends. The grey region is the 95% confidence interval for the regression line."

# show figure from PNG file
knitr::include_graphics(here("analysis",
            "figures",
            "fig-requirements-per-year.png"))
```

Over our ten year study period there have been substantial changes in the instructions to applicants in terms of the type and number of documents that are requested by the search committees [@fig-requirements-over-time]. A cover letter and CV are less requested in more recent years, especially after 2018. The requirement for a diversity statement is rare until 2019-2020, peaks around 2020-2021, then decreases towards the present. Requests for names of recommenders (either zero or three names, rarely only two names) reaches a maximum during 2019-2020 then decreases towards the present. The requirement for a research statement and teaching statement increases after 2015-2016, and becomes more frequent in job ads in more recent years. Requests for course descriptions, syllabus samples, teaching evaluations, transcripts and writing samples are consistently low over time (not shown here).

```{r}
#| label: requirements-by-position 

# do the requirements differ for associate positions 
jobdata_requirements_by_rank <- 
jobdata %>% 
  mutate(position_title = case_when(
    str_detect(title_of_position_tenure_track_jobs_only, 
               "associate") ~ "associate",
    str_detect(title_of_position_tenure_track_jobs_only, 
               "assistant") ~ "assistant",
    str_detect(title_of_position_tenure_track_jobs_only, 
               "full") ~ "full"))  %>% 
  select(position_title,
         starts_with("documents_requested")) %>% 
  pivot_longer(-position_title) %>% 
  mutate(value = case_when(
    value == "Not requested in the job ad" ~ 0,
    value == "One" ~ 1,
    value == "Two (e.g. two syllabi)" ~ 2,
    value == "Three" ~ 3,
    .default = 0
  )) %>% 
  filter(!is.na(position_title))   %>% 
  mutate(position_title = str_to_title(position_title)) %>% 
    # trim names a bit
  mutate(name = str_remove(name, "documents_requested_")) %>% 
  mutate(name = str_replace_all(name, "_", " ")) 

jobdata_requirements_by_rank_means <- 
  jobdata_requirements_by_rank %>% 
  group_by(position_title,
           name) %>% 
  summarise(mean = mean(value))

p_req_rank <- 
ggplot() +
    geom_jitter(data = jobdata_requirements_by_rank,
                  aes(position_title, 
                      value),
                height = 0.05,
                alpha = 0.1) +
    geom_point(data = jobdata_requirements_by_rank_means,
               aes(position_title,
                   mean),
               size = 4,
               colour = "red") +
  facet_wrap( ~ name,
              scales = "free_y") +
   scale_y_continuous(breaks = integer_breaks()) +
  xlab("") +
  ylab("Number requested in job ad") +
  theme_minimal()

ggsave(filename = here("analysis",
            "figures", 
            "fig-requirements-by-rank.png"),
       plot = p_req_rank,
       bg ="white",
       h = 6, # experiment with h and w to get the right size and proportion 
       w = 8,
       units = "in",
       dpi = 900) # make the image nice and crisp
```

```{r}
#| label: fig-requirements-by-position
#| fig-cap: "Variation in application requirements by academic position. Each point represents an individual job ad. The points have been jittered to avoid overlap. The red point is the mean value for each group."

# show figure from PNG file
knitr::include_graphics(here("analysis",
            "figures",
            "fig-requirements-by-rank.png"))
```

@fig-requirements-by-position

# Discussion

# Conclusion

# Acknowledgements

<!-- The following line inserts a page break  -->

\newpage

# References

<!-- The following line ensures the references appear here for the MS Word or HTML output files, rather than right at the end of the document (this will not work for PDF files):  -->

::: {#refs}
:::

\newpage

### Colophon

This report was generated on `r Sys.time()` using the following computational environment and dependencies:

```{r}
#| label: colophon
#| cache: false

# which R packages and versions?
if ("devtools" %in% installed.packages()) devtools::session_info()
```

The current Git commit details are:

```{r}
# what commit is this file at? 
if ("git2r" %in% installed.packages() & git2r::in_repository(path = ".")) git2r::repository(here::here())  
```

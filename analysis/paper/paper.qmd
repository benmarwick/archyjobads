---
title: "Title Goes Here"
author:
  - Jane Doe:
      correspondence: "yes"
      email: janedoe@fosg.org
      orcid: 0000-0003-1689-0557
      institute:
        - fosg
        - fop
  - John Q. Doe:
      institute: fosg
      orcid: 0000-0003-1689-0558
  - Peder Ås:
      institute: fosg
      orcid: 0000-0003-1689-0559
  - Juan Pérez:
      orcid: 0000-0003-1689-0551
      institute:
        - name: Acme Corporation
  - Max Mustermann:
      orcid: 0000-0003-1689-0552
institute:
  - fosg:
      name: Formatting Open Science Group
      address: 23 Science Street, Eureka, Mississippi, USA
  - fop: Federation of Planets
title-block-published: "Last updated"  
date: now
date-format: long
format: 
  docx:
    reference-doc: "../templates/template.docx" # Insert path for the DOCX file
execute:
  echo: true
  warning: false
  message: false
  comment: "#>"
  fig-path: "../figures/"
  fig-dpi: 600
filters:
  - ../templates/scholarly-metadata.lua
  - ../templates/author-info-blocks.lua
  - ../templates/pagebreak.lua
bibliography: references.bib
csl: "../templates/journal-of-archaeological-science.csl" # Insert path for the bib-style
abstract: |
  Text of abstract
keywords: |
  keyword 1; keyword 2; keyword 3
highlights: |
  These are the highlights. 
---

<!-- This is the format for text comments that will be ignored during renderings. Do not put R code in these comments because it will not be ignored. -->

<!-- With the following code you can access and display values from the yml header above. -->

Keywords: `r rmarkdown::metadata$keywords`

Highlights: `r rmarkdown::metadata$highlights`

<!-- The actual document text starts here: -->

# Introduction

Here is a citation [@Marwick2017]

# Background

# Methods

# Results

<!-- Here's some example analysis code: -->

```{r}
#| label: get-data

library(tidyverse)
library(here)
library(ggbeeswarm)
# This CSV file was downloaded from our data sheet here
# https://docs.google.com/spreadsheets/d/1Jwe3UqJyedrV-QWlwR_44__t4xBVrCfxGyhXdi3E0sg/edit?resourcekey#gid=1686084773
# note that you may need to download it again to get the latest updates!

jobdata <- read_csv(here::here('analysis/data/raw_data/Tenure Track Job Advertisements in Archaeology (Responses) - Form Responses 1.csv')) %>% 
  # simplify the column names 
  janitor::clean_names()

total_number_of_ads_in_our_sample <- nrow(jobdata)
```

We have `r total_number_of_ads_in_our_sample` job advertisements in our sample

```{r}
#| label: fig-how-many-jobs-per-year
#| fig-cap: "Number of tenure-track archaeology faculty job ads posted each year"

# we can get the year from the URL to the Academic Job Ads Wiki

year_ad_posted <- 
jobdata %>% 
  pull(url_to_data_source_e_g_paste_in_url_to_the_jobs_wiki_page) %>% 
  str_extract(.,  "[[0-9]]{4}-[[0-9]]{4}|2021-22") %>% 
  str_replace("2021-22",  "2021-2022")
 # fix for 2021-22 DONE!
 # fix for 2023 DONE!

jobdata <- 
  jobdata %>% 
  mutate(year_ad_posted = year_ad_posted) %>% 
  drop_na(year_ad_posted)

fig_how_many_jobs_per_year <- 
ggplot(jobdata) +
  aes(year_ad_posted) +
  geom_bar() +
  scale_x_discrete(name = "Academic Year") +
  ylab("Number of\ntenure track job ads") +
  theme_minimal(base_size = 14)


```

@fig-how-many-jobs-per-year shows how many jobs per year in our sample

```{r}
#| label: fig-how-many-jobs-per-year-by-rank
#| fig-cap: "Proportion of tenure-track archaeology faculty jobs per year by rank"

# how many jobs of each rank per year?

jobdata <-
jobdata %>%
  # simplify rank descriptions
  mutate(title_of_position_tenure_track_jobs_only = tolower(title_of_position_tenure_track_jobs_only)) %>%
  mutate(job_title_simple = case_when(
   str_detect(title_of_position_tenure_track_jobs_only,
              "assistant prof|asst. prof|asst prof") ~ "Assistant Professor",
   str_detect(title_of_position_tenure_track_jobs_only,
              "associate prof|assoc. prof") ~ "Associate Professor",
   str_detect(title_of_position_tenure_track_jobs_only,
              "full prof") ~ "Full Professor",
   str_detect(title_of_position_tenure_track_jobs_only,
              "assistant or associate prof|assistant/associate prof") ~ "Assistant or Associate Professor",
   str_detect(title_of_position_tenure_track_jobs_only,
              "open rank|open-rank|assistant, associate, or full prof|assistant prof, associate prof, or prof") ~ "Open Rank",
   .default = "Other (Curator, Director, etc.)"))

# explore over time
fig_prop_by_job_title_per_year <- 
jobdata %>%
  group_by(year_ad_posted) %>%
  count(job_title_simple) %>%
  mutate(prop = n / sum(n)) %>%
  ggplot() +
  aes(year_ad_posted,
      prop,
      group = job_title_simple,
      colour = job_title_simple) +
  geom_line(linewidth = 2) +
  theme_minimal(base_size = 14) +
  xlab("") +
  ylab("Proportion of\nall tenure-track ads") +
  theme(legend.position = c(0.5, 0.5)) +
  guides(colour = guide_legend(nrow=2,
                               byrow=TRUE,
                               "Job title")) +
   guides(x = "none")


```


```{r}
#| label: ratio-tt-to-non-tt

# ratio of tenure-track to untenured positions
# base URL changes after 2018_2019

base_url_to_2019 <- "https://academicjobs.fandom.com/wiki/Archaeology_Jobs_"
base_url_after_2020 <- "https://academicjobs.fandom.com/wiki/Archaeology_"

# starts at 2010-2011
# fix for 2021-22
# base UR

years_to_2019 <- map_chr(2013:2019, ~str_glue('{.x}-{.x +1}'))
years_after_2020 <- map_chr(2020:2022, ~str_glue('{.x}-{.x +1}'))
# though it seems to start at 2007-8: https://academicjobs.fandom.com/wiki/Archaeology_07-08

# make a set of URLs for each page for each year
urls_for_each_year <- c(str_glue('{base_url_to_2019}{years_to_2019}'), 
                        str_glue('{base_url_after_2020}{years_after_2020}')) %>% 
    str_replace("2021-2022", "2021-22")

library(rvest)

# all years
urls_for_each_year_headers <- 
map(urls_for_each_year,
    ~.x %>% 
      read_html() %>% 
      html_nodes('.mw-headline') %>% 
      html_text())

# keep only headings that are actual jobs, they include the terms:
job_headings <- c("college", "university")

total_number_of_jobs_per_year <- 
  map(urls_for_each_year_headers,
      ~str_subset(tolower(.x),
          paste0(job_headings, collapse = "|")))

total_number_of_jobs_per_year_n <- 
map_int(total_number_of_jobs_per_year, length)

total_number_of_jobs_per_year_tbl <- 
tibble(
  url_to_data_source_e_g_paste_in_url_to_the_jobs_wiki_page = urls_for_each_year,
  total_number_of_jobs_per_year = total_number_of_jobs_per_year_n
)

# count of TT jobs per year from our manual data collection,
# join with our total number of all jobs by scraping
count_of_tt_jobs_per_year_from_our_form <- 
jobdata %>% 
  group_by(url_to_data_source_e_g_paste_in_url_to_the_jobs_wiki_page) %>% 
  tally() %>% 
  right_join(total_number_of_jobs_per_year_tbl) %>% 
  rename(n_tt_jobs  = n,
         n_total_jobs = total_number_of_jobs_per_year) %>% 
  mutate(n_non_tt_jobs = n_total_jobs - n_tt_jobs,
         ratio_tt_2_ntt = n_tt_jobs / n_non_tt_jobs) %>% 
  mutate(year = str_extract(url_to_data_source_e_g_paste_in_url_to_the_jobs_wiki_page,  "[[0-9]]{4}-[[0-9]]{4}|2021-22")) %>%  
  mutate(year = ifelse(year =="2021-22",  "2021-2022", year)) 

# draw plot
fig_ratio_tt_2_ntt_jobs_per_year <- 
  ggplot(count_of_tt_jobs_per_year_from_our_form) +
  aes(year, 
      group = 1,
      ratio_tt_2_ntt) +
  geom_line(linewidth = 2) +
  geom_hline(yintercept = 1,
             colour = "red") +
  annotate("text", 
           x = 3, 
           y = 1.3, 
           label = "1:1 ratio",
           colour = "red") +
  labs(y = "Ratio of tenure-track to\nnon-tenure track and other",
       x = "") +
  theme_minimal(base_size = 14) +
   guides(x = "none")
  

```


```{r}
# save these three plots as one set
library(cowplot)
plot_grid(
  fig_ratio_tt_2_ntt_jobs_per_year,
  fig_prop_by_job_title_per_year,
  fig_how_many_jobs_per_year,
  ncol = 1,
  align = "hv",
  axis = "lr"
)

ggsave(here("analysis",
            "figures", 
            "fig-panel-per-year.png"),
       bg ="white",
       h = 11, # experiment with h and w to get the right size and proportion 
       w = 20,
       units = "in",
       dpi = 900) # make the image nice and crisp

```


```{r}
#| label: fig-requirements-over-time

jobdata_requirements <- 
jobdata %>% 
  select(year_ad_posted,
         starts_with("documents_requested")) %>% 
  pivot_longer(-year_ad_posted) %>% 
  mutate(value = case_when(
    value == "Not requested in the job ad" ~ 0,
    value == "One" ~ 1,
    value == "Two (e.g. two syllabi)" ~ 2,
    value == "Three" ~ 3,
    .default = 0
  ))  %>% 
  # trim names a bit
  mutate(name = str_remove(name, "documents_requested_")) %>% 
  mutate(name = str_replace_all(name, "_", " "))

jobdata_requirements_means <- 
jobdata_requirements %>% # average number requested per year
  group_by(year_ad_posted, 
           name) %>% 
  summarise(mean_n = mean(value))

integer_breaks <- function(n = 5, ...) {
  fxn <- function(x) {
    breaks <- floor(pretty(x, n, ...))
    names(breaks) <- attr(breaks, "labels")
    breaks
  }
  return(fxn)
}

ggplot(jobdata_requirements_means) +
  aes(year_ad_posted, 
      mean_n,
      group = name) +
  geom_smooth(linewidth = 2,
              colour = "black") +
  geom_jitter(data = jobdata_requirements,
             aes(year_ad_posted, 
                 value),
             alpha = 0.1,
             height = 0.2,
             width =  0.1) +
  facet_wrap(~name,
             scales = "free_y",
             nrow = 2) +
  xlab("Year") +
  ylab("Number requested in job ad") +
  scale_y_continuous(breaks = integer_breaks()) +
  theme_minimal(base_size = 14) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) 

ggsave(here("analysis",
            "figures", 
            "fig-requirements-per-year.png"),
       bg ="white",
       h = 10, # experiment with h and w to get the right size and proportion 
       w = 25,
       units = "in",
       dpi = 900) # make the image nice and crisp
  
```



```{r}
#| label: fig-requirements-by-position 

# do the requirements differ for associate positions 
jobdata_requirements_by_rank <- 
jobdata %>% 
  mutate(position_title = case_when(
    str_detect(title_of_position_tenure_track_jobs_only, 
               "associate") ~ "associate",
    str_detect(title_of_position_tenure_track_jobs_only, 
               "assistant") ~ "assistant",
    str_detect(title_of_position_tenure_track_jobs_only, 
               "full") ~ "full"))  %>% 
  select(position_title,
         starts_with("documents_requested")) %>% 
  pivot_longer(-position_title) %>% 
  mutate(value = case_when(
    value == "Not requested in the job ad" ~ 0,
    value == "One" ~ 1,
    value == "Two (e.g. two syllabi)" ~ 2,
    value == "Three" ~ 3,
    .default = 0
  )) %>% 
  filter(!is.na(position_title)) 

jobdata_requirements_by_rank_means <- 
  jobdata_requirements_by_rank %>% 
  group_by(position_title,
           name) %>% 
  summarise(mean = mean(value))

ggplot() +
    geom_jitter(data = jobdata_requirements_by_rank,
                  aes(position_title, 
                      value),
                height = 0.05,
                alpha = 0.1) +
    geom_point(data = jobdata_requirements_by_rank_means,
               aes(position_title,
                   mean),
               size = 4,
               colour = "red") +
  facet_wrap( ~ name,
              scales = "free_y") +
  theme_minimal()
```


```{r}
#| label: fig-geographic-focus-by-year 

# geographic focus by year

library(googlesheets4)
library(stringi)

geographic_foci <-
read_sheet("https://docs.google.com/spreadsheets/d/1AHq49pIyChcgJ7rawe6KMWkdIBXydCamvg8Jslob8Ec/edit#gid=0")

geographic_foci_clean <-
  map(
   str_split(geographic_foci$`From the data`, ";"),
   ~.x %>%
     str_squish() %>%
     stri_remove_empty())

jobdata_geo <-
  jobdata %>%
  select(geographic_focus_of_position)

jobdata_geo <-
  # add one column for each geo region in our categories
cbind(jobdata_geo,
      setNames( lapply(geographic_foci$Category2, function(x) x=NA),
                geographic_foci$Category2) )

for(i in 1:length(geographic_foci$Category2)){

  this_location <- geographic_foci$Category2[i]

  # create the pattern to search for
  x <- paste0(geographic_foci_clean[[i]], collapse = "|")

  # do the search through all the job ads for that pattern
  y <- str_detect(jobdata_geo$geographic_focus_of_position,
             x)

  # assign back to our data frame in the appropriate location column
  jobdata_geo[, this_location] <- y

}

# BM TODO: check for job ads that have a location, but we're not getting it

united_states_regions <-
c( "Northeastern US",
   "Midwest US",
   "Southeast US",
   "Southwest US",
   "Western US",
   "Southern US",
   "Eastern US"  )

jobdata_geo_year <-
jobdata %>%
  bind_cols(jobdata_geo) %>%
  select(year_ad_posted,
         geographic_foci$Category2) %>%
  pivot_longer(-year_ad_posted) %>%
  drop_na()

# how many times each location mentioned?
jobdata_geo_year %>%
  group_by(name) %>%
  summarise(n = sum(value)) %>%
  arrange(desc(n)) %>%
  ggplot() +
  aes(reorder(name, n),
      n)+
  geom_col() +
  xlab("") +
  theme_minimal() +
  coord_flip()

# explore trends over time. put a point on the max year
jobdata_geo_year_tally <-
jobdata_geo_year %>%
 # exclude those with <20 ads
  filter(!name %in% c("Canada",
                      "Americas",
                      "Arctic",
                      "Oceania",
                      "Eastern US",
                      "Southern US",
                      "Midwest US",
                      "Northeastern US"
                      )) %>%
  group_by(year_ad_posted,
           name) %>%
  summarise(n = sum(value)) %>%
  mutate(prop = n / sum(n))

jobdata_geo_year_tally_max <-
  jobdata_geo_year_tally %>%
  group_by(
           name ) %>%
  filter(prop == max(prop))

library(ggrepel)

ggplot() +
  geom_smooth(data =  jobdata_geo_year_tally,
            aes(year_ad_posted,
                 prop,
                 group = name,
                 colour = name),
            size = 2,
           se = FALSE 
           ) +
  xlab("Year") +
  ylab("Proportion of all ads") +
  guides(colour = guide_legend("Geographic\nfocus",
                               label.position = "bottom")) +
    theme_minimal( base_size = 14) +
  theme(legend.position="bottom") 

ggsave(here("analysis",
            "figures", 
            "fig-geo-focus-by-year.png"),
       bg ="white",
       h = 10, # experiment with h and w to get the right size and proportion 
       w = 12,
       units = "in",
       dpi = 900) # make the image nice and crisp)


# what about within the US
jobdata_geo_us_year <-
  jobdata %>%
  bind_cols(jobdata_geo) %>%
  select(year_ad_posted,
         geographic_foci$Category2) %>%
  pivot_longer(-year_ad_posted) %>%
  drop_na()

```


```{r}

# topical focus by year

library(googlesheets4)
library(stringi)

topical_foci <-
  read_sheet("https://docs.google.com/spreadsheets/d/1AHq49pIyChcgJ7rawe6KMWkdIBXydCamvg8Jslob8Ec/edit#gid=0",
             sheet = "topic")

topical_foci_clean <-
  map(
    str_split(topical_foci$`From the data`, ";"),
    ~.x %>%
      str_squish() %>%
      stri_remove_empty() %>%
      str_to_lower)

jobdata_topic <-
  jobdata %>%
  select(topical_focus_of_position) %>%
  mutate(topical_focus_of_position = str_to_lower(topical_focus_of_position))

jobdata_topic <-
  # add one column for each topic in our categories
  cbind(jobdata_topic,
        setNames( lapply(topical_foci$Category, function(x) x=NA),
                  topical_foci$Category) )

for(i in 1:length(topical_foci$Category)){

  this_topic <- topical_foci$Category[i]

  # create the pattern to search for
  x <- paste0(topical_foci_clean[[i]], collapse = "|")

  # do the search through all the job ads for that pattern
  y <- str_detect(jobdata_topic$topical_focus_of_position,
                  x)

  # assign back to our data frame in the appropriate location column
  jobdata_topic[, this_topic] <- y

}

jobdata_topic_year <-
  jobdata %>%
  bind_cols(jobdata_topic) %>%
  select(year_ad_posted,
         topical_foci$Category) %>%
  pivot_longer(-year_ad_posted) %>%
  drop_na()

# how many times each location mentioned?
jobdata_topic_year %>%
  group_by(name) %>%
  summarise(n = sum(value)) %>%
  arrange(desc(n)) %>%
  ggplot() +
  aes(reorder(name, n),
      n)+
  geom_col() +
  xlab("") +
  theme_minimal() +
  coord_flip()

# explore trends over time. put a point on the max year
jobdata_topic_year_tally <-
  jobdata_topic_year %>%
  # exclude those with <20 ads
  filter(!name %in% c("Digital Archaeology",
                      "Pleistocene archaeology",
                      "Mesoamerican Archaeology",
                      "Biological anthropology",
                      "Archaeological theory",
                      "Evolutionary anthropology",
                      "North American archaeology"
  )) %>%
  group_by(year_ad_posted,
           name) %>%
  summarise(n = sum(value)) %>%
  mutate(prop = n / sum(n))

jobdata_topic_year_tally_max <-
  jobdata_topic_year_tally %>%
  group_by(
    name ) %>%
  filter(prop == max(prop))

library(ggrepel)

ggplot() +
  geom_smooth(data =  jobdata_topic_year_tally,
            aes(year_ad_posted,
                prop,
                group = name,
                colour = name),
            size = 2,
           span = 0.7,
            se = FALSE) +
  xlab("Year") +
  ylab("Proportion of all ads") +
  guides(colour = guide_legend("Topic\nfocus",
                               label.position = "bottom")) +
    theme_minimal( base_size = 14) +
  theme(legend.position="bottom") 

ggsave(here("analysis",
            "figures", 
            "fig-topic-focus-by-year.png"),
       bg ="white",
       h = 10, # experiment with h and w to get the right size and proportion
       w = 12,
       units = "in",
       dpi = 900) # make the image nice and crisp))

```

# Discussion

# Conclusion

# Acknowledgements

<!-- The following line inserts a page break  -->

\newpage

# References

<!-- The following line ensures the references appear here for the MS Word or HTML output files, rather than right at the end of the document (this will not work for PDF files):  -->

::: {#refs}
:::

\newpage

### Colophon

This report was generated on `r Sys.time()` using the following computational environment and dependencies:

```{r}
#| label: colophon
#| cache: false

# which R packages and versions?
if ("devtools" %in% installed.packages()) devtools::session_info()
```

The current Git commit details are:

```{r}
# what commit is this file at? 
if ("git2r" %in% installed.packages() & git2r::in_repository(path = ".")) git2r::repository(here::here())  
```
